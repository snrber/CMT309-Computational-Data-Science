# -*- coding: utf-8 -*-
"""Q3.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gQSNXQWYnMGlSP5VpCjo6uMCHsI3y0oo

Docstring
This file contains Question 3. The required files are inputted using variables
to improve readability.

tags = "alice_tags.txt"
words = "alice_words.txt"

Q3.1:
This solution reads the files into a list as is, then the next line converts it
into lower case values as per the performa. Similar to the previous function
created, getwordssequence has a preliminary step, creating the list at "\n"
characters to ensure the output is as desired. Then, it can create the list
at "<SEP>". Then, the function is the same as gettagssequence.

Q3.2:
For loop iterates through tags list, adds each value to matches_list
and uses re.finditer() to return an iterator and go through tags to see if
the value added to matches_list and the value in finditer() match the
regex.

Q3.3:
Creates various variables to store values, then iterates through list of tuples
to find corresponding values in the list.
"""

#C22106798
#Q3

import re
import numpy as np
from google.colab import drive
drive.mount('/content/gdrive')

tags = open(r'/content/gdrive/My Drive/Python coursework/Question 3/alice_tags.txt').read()
words = open(r'/content/gdrive/My Drive/Python coursework/Question 3/alice_words.txt').read()

#Q3.1

def gettagssequence(tagged_file):
  
  tags = open(r'/content/gdrive/My Drive/Python coursework/Question 3/alice_tags.txt').read()
  
  #Read file into list
  tags_list_upper = tags.replace("<SEP>", "").split("\n")

  #Lower case
  tags_list = [tags_list_upper.lower() for tags_list_upper in tags_list_upper]

  return tags_list

def getwordssequence(words_file):

  words = open(r'/content/gdrive/My Drive/Python coursework/Question 3/alice_words.txt').read()

  #List creation at "\n"
  words_list_upper = re.split("\n", words)

  #List creation at <SEP>
  words_list_upper = [words_list_upper.split("<SEP>") for words_list_upper in words_list_upper]
  
  #Lower case
  words_sequences = [[word.lower() for word in words_list_upper[x]] for x in range(len(words_list_upper))]

  return words_sequences

#Q3.2

def find_positions(tags_sequences):
  tags_sequences = open(r'/content/gdrive/My Drive/Python coursework/Question 3/alice_tags.txt').read()

  tags = re.sub("<SEP>", "", tags_sequences).split("\n") #Creates a string at seperators 
  matches_list = [] #Creates new list for matches

  #For loop iterates through tags list, adds each value to matches_list
  #and uses re.finditer() to return an iterator and go through tags to see if
  #the value added to matches_list and the value in finditer() match the
  #regex
  for i in range(len(tags)): 
    matches_list.append([])
    for noun_phrase in re.finditer(r"J?[N]N?", tags[i]):
      matches_list[i].append(noun_phrase.span())

  return matches_list

#Q3.3

def find_noun_phrase(input_word, matches_list, words_sequences):
    for word_list in words_sequences:
      if input_word in word_list:
        input_word_line_index = words_sequences.index(word_list) #Line number
        input_word_line = words_sequences[input_word_line_index] #Input word sentence as a list of strings
        input_word_index = word_list.index(input_word) #Index of the word in the line
        tuple_list = matches_list[input_word_line_index] #Tuple list corresponding with desired word
        x = [] #Array to contain words for output

        #Iterate through list of tuples and append corresponding line number 
        for tup in tuple_list: 
          for i in range(tup[0], tup[1]):
            if input_word == input_word_line[i]:
              for j in range(tup[0], tup[1]):
                x.append(input_word_line[j])

        y = " ". join(x)

        print(input_word_line_index + 1, "\b:", y)
